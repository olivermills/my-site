<!DOCTYPE html>
<html lang="en-US">
	<head>
		<meta charset="UTF-8">
		<meta name="viewport" content="width=device-width,initial-scale=1">

		
		<title>Web Scraping and Word Clouds &middot; Oliver Mills</title>
		

		
			
		

		

		
		


<link href='//cdn.bootcss.com/highlight.js/9.11.0/styles/github.min.css' rel='stylesheet' type='text/css' />



		

		<link rel="stylesheet" href="../../../../font-awesome/css/font-awesome.min.css" type="text/css">
		<link rel="stylesheet" href="../../../../css/poole.css">
		<link rel="stylesheet" href="../../../../css/syntax.css">
		<link rel="stylesheet" href="../../../../css/hyde.css">
		
		
		<link href="" rel="alternate" type="application/rss+xml" title="Oliver Mills">
		<link href="../../../../2019/03/09/web-scraping-and-word-clouds" rel="canonical">
		
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-134759200-1', 'auto');
	
	ga('send', 'pageview');
}
</script>

	</head>

</script>
	<body class="theme-base-0d  h-entry">
		<main class="content container" role="main">
			<article class="post">
				<header>
					<a class="u-url" href="../../../../2019/03/09/web-scraping-and-word-clouds">
						<h1 class="post-title p-name">Web Scraping and Word Clouds</h1>
					</a>
					<time class="post-date dt-published" datetime="2019-03-09T00:00:00Z">Saturday, 9 March 2019</time>
				</header>
				<main class="post-content e-content">
					


<p>What better way to guage the opinion of the general public than trawling through online comments on articles. The visuals below were created by scraping the comments from an article about the proposed <a href="https://www.stuff.co.nz/business/money/110775274/capital-gains-tax-dirty-little-secrets-behind-the-cgt">capital gains tax</a> in NZ and using R to do some basic text mining and data visualisation.</p>
<div class="figure">
<img src="../../../../wordcloud.png" />

</div>
<p>This wordcloud above shows the overall sentiment of the comments, seperating each word into positive (green) or negative (red) groupings based on the users comments. The size of each word is proportional to the number of times it was mentioned in the comments.</p>
<div class="figure">
<img src="../../../../ngrams.png" />

</div>
<p>This network shows common word couplings mentioned in the comments. We can see common themes in the text and in our case looks like there are two main groupings (a. tax/payments and b. property). Then there’s a bunch of other smaller groupings - ranging from diverse themes such as ‘child support’, ‘weakest link’, ‘john key’ and my favourite: ‘bloody hard yards’.</p>
<p>If we look at the number of times people have commented, some people have commented over 10 times on this article - these are the true keyboard warriors! I’ve also plotted the character length of each comments to see how many words people are writing. The plot shows that some people are writing comments over 1000 characters long - surely there are better things to do in your spare time! <img src="../../../../comments.png" /> <img src="../../../../length.png" /></p>
<p>Here’s the code used to scrape the comments, wrangle the data and create the visualisations. Because the comments section on the stuff website is actually a javascript object I had to use RSelenium to click the ‘See more comments’ button - otherwise I could only access the first 100 comments.</p>
<pre class="r"><code>library(RSelenium)
library(stringr)
library(dplyr)
library(readr)
library(wordcloud)
library(tidytext)
library(reshape2)

#load selenium driver and navigate to the article
driver &lt;- rsDriver()
remDr &lt;- driver[[&quot;client&quot;]]
remDr$navigate(&quot;https://www.stuff.co.nz/business/money/110775274/capital-gains-tax-dirty-little-secrets-behind-the-cgt&quot;)

#expand comments section using css selector
var &lt;- remDr$findElement(&#39;css selector&#39;,&#39;#js-story-comments &gt; div.gig-comments-more&#39;)
var$clickElement()

#find the comments element and extract comment text
var &lt;- remDr$findElement(&#39;css selector&#39;,&#39;#js-story-comments&#39;)

#allow the page to load and grab the text
Sys.sleep(10)
raw.comments &lt;- var$getElementText()

#wrangle the comments + name from the raw string
names &lt;- str_match_all(raw.comments, &#39;ago\\n([[:alnum:]]*)\\n&#39;)[[1]][,2]
comments &lt;- str_match_all(raw.comments, &#39;ago\\n([[:alnum:]]*)\\n(.*)&#39;)[[1]][,3]

#store in data frame
comments.df &lt;- data.frame(names,comments)
comments.df$comments &lt;- as.character(comments.df$comments)
comments.df$names &lt;- as.character(comments.df$names)

#exploratory data analysis - could go into more detail here but will save that for a rainy day
summary(as.data.frame(comments.df$names))
plot(nchar(as.character(comments.df$comments)),main=&quot;Average Character Length of Comments&quot;,ylab=&quot;Length&quot;,col=60)

#word cloud - seperate the tokens, remove stop words
#grab the sentiment score and group according to pos/neg
set.seed(101)
comments.df %&gt;%
  unnest_tokens(word, comments) %&gt;%
  anti_join(stop_words) %&gt;%
  inner_join(get_sentiments(&quot;bing&quot;)) %&gt;%
  count(word, sentiment, sort=TRUE) %&gt;%
  acast(word~sentiment, value.var=&quot;n&quot;, fill=0) %&gt;%
  comparison.cloud(rot.per=.2, colors = c(&quot;tomato&quot;, &quot;springgreen4&quot;), 
                   max.words=200,title.size = 0.5,scale=c(5,.5))

## network analysis
# here we are looking at &#39;ngrams&#39; - an n-gram is a contiguous sequence of n items from a given sample of text or speech.
# the code below creates a nice network visual for 2 word sequences
test_bigram &lt;- comments.df %&gt;%
  unnest_tokens(bigram, comments, token=&#39;ngrams&#39;, n=2)

test_bigram %&gt;%
  count(bigram, sort=TRUE)

library(tidyr)
bigrams_separated &lt;- test_bigram %&gt;%
  separate(bigram, c(&quot;word1&quot;, &quot;word2&quot;), sep=&quot; &quot;)

bigrams_filtered &lt;- bigrams_separated %&gt;%
  filter(!word1 %in% stop_words$word) %&gt;%
  filter(!word2 %in% stop_words$word)

bigrams_counts &lt;- bigrams_filtered %&gt;%
  count(word1, word2, sort=TRUE)

bigrams_united &lt;- bigrams_filtered %&gt;%
  unite(bigram, word1, word2, sep=&quot; &quot;)

#bigram relationships
library(igraph)
bigram_graph &lt;- bigrams_counts %&gt;%
  filter(n&gt;1) %&gt;%
  graph_from_data_frame()

bigram_graph

library(ggraph)
set.seed(2017)
a &lt;- grid::arrow(type=&quot;closed&quot;, length=unit(.05, &quot;inches&quot;)
)
ggraph(bigram_graph, layout=&quot;fr&quot;) +
  geom_edge_link(show.legend=FALSE,
                 arrow=a) +
  geom_node_point(size=5, color=&quot;light blue&quot;) +
  geom_node_text(aes(label=name), vjust=1, hjust=1) + theme_void()</code></pre>

				</main>
				<footer class="footer">
					
					
				</footer>
			</article>
		</main>
				<aside class="sidebar">
			<div class="container sidebar-sticky">
				<header class="sidebar-about h-card vcard p-author">
					
					<a class="u-url u-uid" rel="me" href="../../../../">
						<img class="u-photo" src="../../../../me.jpg" width=128 height=128 />
					</a>
					

					
					<span class="site-title u-name fn">
					  <a class="u-url u-uid" rel="me" href="../../../../">Oliver Mills</a>
				  </span>
					

					<p class="lead p-note">
						 A personal website built through Hugo and blogdown (R Studio). 
					</p>

					<nav>
						<ul class="sidebar-nav">
							
							<li><a href="../../../../about/"> About </a></li>
							
							<li><a href="../../../../post/"> Posts </a></li>
							
							<li><a href="../../../../2019/03/09/web-scraping-and-word-clouds/"> Web Scraping and Word Clouds </a></li>
							
						</ul>
					</nav>

					
						<aside class="contact">
						  
							  <h3 class="contact-head">Contact Me</h3>
						  
							<ul class="contact-list">
								
								<li>
									
		  							<i class='fa fa-envelope fa-fw'></i>
		  							<a href="mailto:olivarski@gmail.com" class="u-email email" rel="me">
		  							  Email
		  							</a>
									
								</li>
								
								<li>
									
									  
		  						    <i class='fa fa-github fa-fw'></i>
		  						  
		  							<a href="https://github.com/olivermills" class="u-url url" rel="me">
		  							  GitHub
		  							</a>
								
								</li>
								
								<li>
									
									  
		  						    <i class='fa fa-linkedin fa-fw'></i>
		  						  
		  							<a href="https://nz.linkedin.com/in/oliver-mills-a2238559" class="u-url url" rel="me">
		  							  LinkedIn
		  							</a>
								
								</li>
								
							</ul>
						</aside>
					
				</header>

				<footer>&copy; 2019. All rights reserved. </footer>
			</div>
		</aside>

		  <footer>
  
  
  
  

  <script src="//cdn.bootcss.com/highlight.js/9.11.0/highlight.min.js"></script>
  
  
  
  <script src="//cdn.bootcss.com/highlight.js/9.11.0/languages/r.min.js"></script>
  <script src="//cdn.bootcss.com/highlight.js/9.11.0/languages/yaml.min.js"></script>
  <script>hljs.configure({languages: []}); hljs.initHighlightingOnLoad();</script>
  

 
  
<script src="../../../../js/math-code.js"></script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    processEscapes: true
  }
});
</script>
<script async src="//cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>


  
  </footer>
  </body>
</html>

	</body>
</html>
